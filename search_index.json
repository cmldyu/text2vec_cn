[
["intro-doc-sim.html", "3 文档相似性 3.1 API 3.2 实例", " 3 文档相似性 文档相似性（或文件之间的距离）是信息检索的中心主题之一。通常人类是如何界定类似文件的？一般而言，文本之所以视为相似，是因为他它们在语义上密切相关并描述类似的概念。另一方面，“相似性”可以用于上下文中的重复性检测。我们会讨论几种常见的度量文本相似性的方法。 3.1 API text2vec包提供两套函数集，以在统一的方式下度量各种距离/相似性。所有方法在编程时都特别注意计算性能和内存使用效率。 sim2(x, y, method) 使用给定的method ，计算矩阵x的每一行和矩阵 y的每一行之间的相似性。 psim2(x, y, method) 使用给定的method，计算矩阵x的行与矩阵y的对应行之间的平行相似性。 dist2(x, y, method) 使用给定的method ，计算矩阵x的每一行和矩阵 y的的每一行之间的距离/相异性。 pdist2(x, y, method) 使用给定的method.，计算矩阵x的行与矩阵y的对应行之间的平行距离或相异度。 函数名有后缀 2 ，是因为相对于base包里的dist()函数，我编写的这些函数要处理两个矩阵而不是一个。 目前可以使用的计算方法有： 杰卡德距离（Jaccard distance） 余弦距离（Cosine distance） 欧氏距离（Euclidean distance） 松散的词汇移动距离（RWMD） 3.2 实例 像往常一样，我们将使用内置的text2vec::moview_review数据集。让我们先把它清理一下： library(stringr) library(text2vec) data(&quot;movie_review&quot;) # select 500 rows for faster running times movie_review = movie_review[1:500, ] prep_fun = function(x) { x %&gt;% # make text lower case str_to_lower %&gt;% # remove non-alphanumeric symbols str_replace_all(&quot;[^[:alnum:]]&quot;, &quot; &quot;) %&gt;% # collapse multiple spaces str_replace_all(&quot;\\\\s+&quot;, &quot; &quot;) } movie_review$review_clean = prep_fun(movie_review$review) 现在，让我们来定义两套文档，我们将在其上使用距离度量模型： doc_set_1 = movie_review[1:300, ] it1 = itoken(doc_set_1$review_clean, progressbar = FALSE) # specially take different number of docs in second set doc_set_2 = movie_review[301:500, ] it2 = itoken(doc_set_2$review_clean, progressbar = FALSE) 我们将在一个向量空间中比较文档。因此，我们需要将目标文档映射到一个共用的向量空间中去。我们将使用基于词汇的向量化模型，因为它更容易解释： it = itoken(movie_review$review_clean, progressbar = FALSE) v = create_vocabulary(it) %&gt;% prune_vocabulary(doc_proportion_max = 0.1, term_count_min = 5) vectorizer = vocab_vectorizer(v) 3.2.1 Jaccard相似 Jaccard相似是对两个集合的一种简单而直观的相似度度量方法。 \\[J(doc_1, doc_2) = \\frac{doc_1 \\cap doc_2}{doc_1 \\cup doc_2}\\] 我们使用文档1和文档2共用词项的数目和两个文档中词项数总和的比值作为文档相似度的计算方法。 为了计算两个文本之间的Jaccard相似性我们需要提供两个文档的DTM（DTM的应在相同的向量空间！）： # 他们应该在同一个向量空间中，因为我们使用了相同的向量生成器来处理它们 # 哈希向量生成器也应该能使用 dtm1 = create_dtm(it1, vectorizer) dim(dtm1) ## [1] 300 2339 dtm2 = create_dtm(it2, vectorizer) dim(dtm2) ## [1] 200 2339 一旦进行了文本在向量空间中的映射（文本向量化），我们就快完成了。只剩下一件事–呼叫sim2()函数！ d1_d2_jac_sim = sim2(dtm1, dtm2, method = &quot;jaccard&quot;, norm = &quot;none&quot;) 检查结果： dim(d1_d2_jac_sim) ## [1] 300 200 d1_d2_jac_sim[1:2, 1:5] ## 2 x 5 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 2 3 4 5 ## 1 0.02142857 . 0.02362205 0.007575758 0.02597403 ## 2 0.01204819 . 0.02898551 0.013698630 0.02061856 此外，我们可以计算平行相似性——两个矩阵的对应的行之间的相似性（矩阵应该有相同的形状）： dtm1_2 = dtm1[1:200, ] dtm2_2 = dtm2[1:200, ] d1_d2_jac_psim = psim2(dtm1_2, dtm2_2, method = &quot;jaccard&quot;, norm = &quot;none&quot;) str(d1_d2_jac_psim) ## Named num [1:200] 0.02143 0 0.00735 0 0.03311 ... ## - attr(*, &quot;names&quot;)= chr [1:200] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... 我们如此定义Jaccard距离或Jaccard相异性：\\[1 -similarity(doc_1，doc_2)\\] sim2()和psim2()有相应的相异度计算功能dist2() pdist2()。需要注意的是，在许多情况下，文档之间的相似性是0，而sim2能利用这一优势——结果矩阵是一个稀疏矩阵。但在大型稀疏矩阵上使用dist2()时就得注意了——稀疏矩阵会变得致密（大量的0被替换成了1） 3.2.2 余弦相似性 经典的计算语言学方法通过计算文档之间的重叠内容来衡量文档的相似性。为此，我们将文档视为词袋，那么每个文档将是一个稀疏向量。我们用向量之间的角度来定义文档之间的“重叠”： \\[similarity(doc_1, doc_2) = cos(\\theta) = \\frac{doc_1 doc_2}{\\lvert doc_1\\rvert \\lvert doc_2\\rvert}\\] 余弦距离/相异我们定义如下： \\[distance(doc_1, doc_2) = 1 - similarity(doc_1, doc_2)\\] 然而要注意的是，这不是一个在数学意义上合适的距离度量，因为它不满足三角不等式，违反了同一律。 余弦相似度的计算和Jaccard相似： d1_d2_cos_sim = sim2(dtm1, dtm2, method = &quot;cosine&quot;, norm = &quot;l2&quot;) 检查结果： dim(d1_d2_cos_sim) ## [1] 300 200 d1_d2_cos_sim[1:2, 1:5] ## 2 x 5 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 2 3 4 5 ## 1 0.02703999 . 0.05063299 0.009500143 0.02753954 ## 2 0.02440658 . 0.06528840 0.034299717 0.03977196 3.2.2.1 余弦相似度与TF-IDF 在进行过变换的矩阵上计算相似性要比在一般的词袋矩阵上要来得有用。一个选择是使用TF-IDF变换。首先让我们创建一个TF-IDF模型： dtm = create_dtm(it, vectorizer) tfidf = TfIdf$new() dtm_tfidf = fit_transform(dtm, tfidf) 计算dtm_tfidf矩阵所有行之间的相似度： d1_d2_tfidf_cos_sim = sim2(x = dtm_tfidf, method = &quot;cosine&quot;, norm = &quot;l2&quot;) d1_d2_tfidf_cos_sim[1:2, 1:5] ## 2 x 5 sparse Matrix of class &quot;dgCMatrix&quot; ## 1 2 3 4 5 ## 1 1.000000000 0.007850872 0.02380155 0.02864296 0.01510648 ## 2 0.007850872 1.000000000 0.01115547 . . 3.2.2.2 使用LSA的余弦相似性 通常TF-IDF /词袋矩阵中含有大量的噪音。应用LSA（潜在语义模型）可以帮助解决这个问题，这样能得到更好的相似性度量。 lsa = LSA$new(n_topics = 100) dtm_tfidf_lsa = fit_transform(dtm_tfidf, lsa) 计算dtm_tfidf_lsa矩阵所有行之间的相似性： d1_d2_tfidf_cos_sim = sim2(x = dtm_tfidf_lsa, method = &quot;cosine&quot;, norm = &quot;l2&quot;) d1_d2_tfidf_cos_sim[1:2, 1:5] ## 1 2 3 4 5 ## 1 1.0000000 0.1699795 0.3688813 0.32099166 0.40136134 ## 2 0.1699795 1.0000000 0.2255580 0.03386272 0.05705503 而“平行相似性”的计算则是： x = dtm_tfidf_lsa[1:250, ] y = dtm_tfidf_lsa[251:500, ] head(psim2(x = x, y = y, method = &quot;cosine&quot;, norm = &quot;l2&quot;)) ## 1 2 3 4 5 6 ## 0.21684991 0.19825612 0.30505693 0.10039684 0.29249032 0.03676142 3.2.3 欧氏距离 欧氏距离在NLP领域不像杰卡德或余弦相似性那样非常有用。但尝试一下不同的度量方法总是值得的。在text2vec中它只能运用在密集矩阵上，这里是例子： x = dtm_tfidf_lsa[1:300, ] y = dtm_tfidf_lsa[1:200, ] m1 = dist2(x, y, method = &quot;euclidean&quot;) 此外，我们可以采用不同的行归一化技术（默认情况下是“L2”规范化）： m2 = dist2(x, y, method = &quot;euclidean&quot;, norm = &quot;l1&quot;) m3 = dist2(x, y, method = &quot;euclidean&quot;, norm = &quot;none&quot;) "]
]
